input size: 4096
rdtsc_overhead set to 57
scalar                        	:     2.047 cycle/op (best)    2.071 cycle/op (avg)
improved scalar               	:     1.926 cycle/op (best)    1.961 cycle/op (avg)
scalar & BMI2                 	:     2.804 cycle/op (best)    4.145 cycle/op (avg)
SSE (lookup: base, pack: naive)	:     1.129 cycle/op (best)    1.137 cycle/op (avg)
SSE (lookup: byte blend, pack: naive)	:     1.282 cycle/op (best)    1.299 cycle/op (avg)
SSE (lookup: incremental, pack: naive)	:     1.058 cycle/op (best)    1.065 cycle/op (avg)
SSE (lookup: pshufb, pack: naive)	:     0.959 cycle/op (best)    0.964 cycle/op (avg)
SSE (lookup: base, pack: multiply-add)	:     0.926 cycle/op (best)    0.965 cycle/op (avg)
SSE (lookup: byte blend, pack: multiply-add)	:     1.004 cycle/op (best)    1.008 cycle/op (avg)
SSE (lookup: incremental, pack: multiply-add)	:     0.927 cycle/op (best)    0.932 cycle/op (avg)
SSE (lookup: pshufb, pack: multiply-add)	:     0.854 cycle/op (best)    0.857 cycle/op (avg)
SSE (lookup: pshufb bitmask, pack: multiply-add)	:     0.923 cycle/op (best)    0.929 cycle/op (avg)
SSE & BMI2 (lookup: base, pack: N/A)	:     1.246 cycle/op (best)    1.281 cycle/op (avg)
SSE & BMI2 (lookup: byte blend, pack: N/A)	:     1.306 cycle/op (best)    1.323 cycle/op (avg)
SSE & BMI2 (lookup: incremental, pack: N/A)	:     1.272 cycle/op (best)    1.297 cycle/op (avg)
AVX2 (lookup: base, pack: naive)	:     0.459 cycle/op (best)    0.490 cycle/op (avg)
AVX2 (lookup: byte blend, pack: naive)	:     0.506 cycle/op (best)    0.508 cycle/op (avg)
AVX2 (lookup: pshufb, pack: naive)	:     0.444 cycle/op (best)    0.454 cycle/op (avg)
AVX2 (lookup: base, pack: multiply-add)	:     0.329 cycle/op (best)    0.336 cycle/op (avg)
AVX2 (lookup: byte blend, pack: multiply-add)	:     0.351 cycle/op (best)    0.412 cycle/op (avg)
AVX2 (lookup: pshufb, pack: multiply-add)	:     0.230 cycle/op (best)    0.264 cycle/op (avg)
AVX2 (lookup: pshufb bitmask, pack: multiply-add)	:     0.222 cycle/op (best)    0.232 cycle/op (avg)
AVX2 & BMI2 (lookup: base, pack: N/A)	:     1.013 cycle/op (best)    1.031 cycle/op (avg)
AVX2 & BMI2 (lookup: byte blend, pack: N/A)	:     1.003 cycle/op (best)    1.012 cycle/op (avg)
AVX512 (gather)               	:     0.961 cycle/op (best)    0.975 cycle/op (avg)
AVX512 (store: vectorized) (lookup: vectorized, pack: improved)	:     0.721 cycle/op (best)    0.726 cycle/op (avg)
AVX512 (store: scatter) (lookup: vectorized, pack: improved)	:     0.703 cycle/op (best)    0.714 cycle/op (avg)
AVX512BW (lookup: N/A, pack: multiply-add)	:     0.142 cycle/op (best)    0.144 cycle/op (avg)
input size: 4096
rdtsc_overhead set to 29
scalar                        	:     1.023 cycle/op (best)    1.122 cycle/op (avg)
improved scalar               	:     1.025 cycle/op (best)    1.079 cycle/op (avg)
scalar & BMI2                 	:     2.194 cycle/op (best)    2.264 cycle/op (avg)
SSE (lookup: base, pack: naive)	:     1.012 cycle/op (best)    1.028 cycle/op (avg)
SSE (lookup: byte blend, pack: naive)	:     1.151 cycle/op (best)    1.155 cycle/op (avg)
SSE (lookup: incremental, pack: naive)	:     0.953 cycle/op (best)    0.961 cycle/op (avg)
SSE (lookup: pshufb, pack: naive)	:     0.862 cycle/op (best)    0.867 cycle/op (avg)
SSE (lookup: base, pack: multiply-add)	:     0.933 cycle/op (best)    0.937 cycle/op (avg)
SSE (lookup: byte blend, pack: multiply-add)	:     1.012 cycle/op (best)    1.018 cycle/op (avg)
SSE (lookup: incremental, pack: multiply-add)	:     0.933 cycle/op (best)    0.937 cycle/op (avg)
SSE (lookup: pshufb, pack: multiply-add)	:     0.860 cycle/op (best)    0.865 cycle/op (avg)
SSE (lookup: pshufb bitmask, pack: multiply-add)	:     0.930 cycle/op (best)    0.934 cycle/op (avg)
SSE & BMI2 (lookup: base, pack: N/A)	:     1.250 cycle/op (best)    1.290 cycle/op (avg)
SSE & BMI2 (lookup: byte blend, pack: N/A)	:     1.313 cycle/op (best)    1.320 cycle/op (avg)
SSE & BMI2 (lookup: incremental, pack: N/A)	:     1.281 cycle/op (best)    1.305 cycle/op (avg)
AVX2 (lookup: base, pack: naive)	:     0.468 cycle/op (best)    0.513 cycle/op (avg)
AVX2 (lookup: byte blend, pack: naive)	:     0.513 cycle/op (best)    0.516 cycle/op (avg)
AVX2 (lookup: pshufb, pack: naive)	:     0.452 cycle/op (best)    0.460 cycle/op (avg)
AVX2 (lookup: base, pack: multiply-add)	:     0.336 cycle/op (best)    0.343 cycle/op (avg)
AVX2 (lookup: byte blend, pack: multiply-add)	:     0.357 cycle/op (best)    0.412 cycle/op (avg)
AVX2 (lookup: pshufb, pack: multiply-add)	:     0.236 cycle/op (best)    0.270 cycle/op (avg)
AVX2 (lookup: pshufb bitmask, pack: multiply-add)	:     0.229 cycle/op (best)    0.232 cycle/op (avg)
AVX2 & BMI2 (lookup: base, pack: N/A)	:     1.020 cycle/op (best)    1.037 cycle/op (avg)
AVX2 & BMI2 (lookup: byte blend, pack: N/A)	:     1.010 cycle/op (best)    1.023 cycle/op (avg)
AVX512 (gather)               	:     0.968 cycle/op (best)    0.973 cycle/op (avg)
AVX512 (store: vectorized) (lookup: vectorized, pack: improved)	:     0.729 cycle/op (best)    0.735 cycle/op (avg)
AVX512 (store: scatter) (lookup: vectorized, pack: improved)	:     0.709 cycle/op (best)    0.719 cycle/op (avg)
AVX512BW (lookup: N/A, pack: multiply-add)	:     0.148 cycle/op (best)    0.151 cycle/op (avg)
input size: 4096
rdtsc_overhead set to 57
scalar                        	:     2.048 cycle/op (best)    2.069 cycle/op (avg)
improved scalar               	:     2.047 cycle/op (best)    2.063 cycle/op (avg)
scalar & BMI2                 	:     3.048 cycle/op (best)    3.561 cycle/op (avg)
SSE (lookup: base, pack: naive)	:     1.227 cycle/op (best)    1.243 cycle/op (avg)
SSE (lookup: byte blend, pack: naive)	:     1.396 cycle/op (best)    1.404 cycle/op (avg)
SSE (lookup: incremental, pack: naive)	:     0.947 cycle/op (best)    1.086 cycle/op (avg)
SSE (lookup: pshufb, pack: naive)	:     0.854 cycle/op (best)    0.858 cycle/op (avg)
SSE (lookup: base, pack: multiply-add)	:     0.926 cycle/op (best)    0.930 cycle/op (avg)
SSE (lookup: byte blend, pack: multiply-add)	:     1.004 cycle/op (best)    1.011 cycle/op (avg)
SSE (lookup: incremental, pack: multiply-add)	:     0.926 cycle/op (best)    0.931 cycle/op (avg)
SSE (lookup: pshufb, pack: multiply-add)	:     0.853 cycle/op (best)    0.868 cycle/op (avg)
SSE (lookup: pshufb bitmask, pack: multiply-add)	:     0.923 cycle/op (best)    0.929 cycle/op (avg)
SSE & BMI2 (lookup: base, pack: N/A)	:     1.244 cycle/op (best)    1.282 cycle/op (avg)
SSE & BMI2 (lookup: byte blend, pack: N/A)	:     1.306 cycle/op (best)    1.313 cycle/op (avg)
SSE & BMI2 (lookup: incremental, pack: N/A)	:     1.270 cycle/op (best)    1.303 cycle/op (avg)
AVX2 (lookup: base, pack: naive)	:     0.461 cycle/op (best)    0.503 cycle/op (avg)
AVX2 (lookup: byte blend, pack: naive)	:     0.505 cycle/op (best)    0.508 cycle/op (avg)
AVX2 (lookup: pshufb, pack: naive)	:     0.445 cycle/op (best)    0.454 cycle/op (avg)
AVX2 (lookup: base, pack: multiply-add)	:     0.329 cycle/op (best)    0.336 cycle/op (avg)
AVX2 (lookup: byte blend, pack: multiply-add)	:     0.351 cycle/op (best)    0.405 cycle/op (avg)
AVX2 (lookup: pshufb, pack: multiply-add)	:     0.233 cycle/op (best)    0.264 cycle/op (avg)
AVX2 (lookup: pshufb bitmask, pack: multiply-add)	:     0.223 cycle/op (best)    0.259 cycle/op (avg)
AVX2 & BMI2 (lookup: base, pack: N/A)	:     1.014 cycle/op (best)    1.032 cycle/op (avg)
AVX2 & BMI2 (lookup: byte blend, pack: N/A)	:     1.002 cycle/op (best)    1.014 cycle/op (avg)
AVX512 (gather)               	:     0.962 cycle/op (best)    0.967 cycle/op (avg)
AVX512 (store: vectorized) (lookup: vectorized, pack: improved)	:     0.722 cycle/op (best)    0.726 cycle/op (avg)
AVX512 (store: scatter) (lookup: vectorized, pack: improved)	:     0.701 cycle/op (best)    0.713 cycle/op (avg)
AVX512BW (lookup: N/A, pack: multiply-add)	:     0.142 cycle/op (best)    0.144 cycle/op (avg)
